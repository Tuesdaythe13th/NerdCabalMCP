# TUESDAY
**AI Safety Engineer & Evaluation Researcher**

Portland, LA, NYC (Remote) • Open to Relocation (London) • [Contact Info](#)

---

## PROFESSIONAL SUMMARY

Published ML engineer and evaluation researcher specializing in **mechanistic interpretability, adversarial ML, and AI safety benchmarking**. Contributor to NIST AI 700-2, MLCommons benchmarks, and UN AI governance frameworks. Unique background in forensic security and complex systems production informs real-time risk assessment and failure mode analysis.

**Core Competencies:** Red Teaming • Evaluation Design • Mechanistic Interpretability • Multi-Agent Safety • Quantum Security

---

## EXPERIENCE

**Research Engineer** | APART Research Studio Lab Fellowship • 2024–Present
- Conducting mechanistic interpretability research on AI cognitive failure modes
- Developed "AI Psychosis" framework for neural forensic analysis of LLM reasoning patterns
- Contributing to experimental MI techniques and cognitive-affective modeling research

**Founder & Director of Research** | ARTIFEX Labs • 2023–Present
- Leading independent AI safety research lab focused on interpretability and quantum systems
- Published research on cascade failures (RecSys 2025), agentic maturity, and evaluation frameworks
- Designed clinical-diagnostic approach to AI safety: "DSM for AI Systems"

**Technical Contributor & Working Group Co-Founder** | MLCommons • 2023–Present
- Co-founded Agentic AI Working Group; released **Agentic Product Maturity Model** (2025)
- Lead contributor: **AILuminate v1.0** benchmark (arXiv:2404.03555) for AI risk & reliability
- Developed **Security Jailbreak Benchmark v0.5** with ISO/IEC 42001-aligned metrics
- Contributing to ARES benchmark for agentic system evaluation

**Technical Red Teamer & Safety Researcher** | Humane Intelligence • 2023–Present
- Contributed to **NIST AI 700-2 ARIA 0.1 Pilot Evaluation** (cited in federal AI guidelines)
- Research contributor: **UNESCO Red Teaming Playbook** for gender bias mitigation
- **Winner, Bias Bounty 4 (2025)** — Advanced Data Track for multimodal auditing
- Policy-relevant audits and multimodal red teaming for frontier AI models

**Quantum Futures Research Contributor** | Open Compute Project (FTI) • 2024–Present
- Post-quantum cryptography and hardware security for quantum data centers
- Quantum error correction, supply chain economics, evaluation frameworks

**Independent AI/ML Consultant** | Self-Employed • 2022–Present
- Mechanistic interpretability, evaluation design, adversarial ML consulting
- Forensic security: incident response, crisis communication, threat assessment

---

## SELECTED PUBLICATIONS

- **Cascade: Human-in-the-Loop Shortcomings Can Increase Risk of Failures in Recommender Systems**
  *FAccTRec@RecSys 2025* • arXiv:2509.20099 • Workshop Presentation

- **AILuminate v1.0: AI Risk & Reliability / Generative AI Safety Benchmark**
  *MLCommons* • arXiv:2404.03555

- **MLCommons Security Jailbreak Benchmark v0.5**
  ISO/IEC 42001-aligned safety metrics

- **NIST AI 700-2: Trustworthy & Responsible AI — ARIA 0.1 Pilot Evaluation Report**
  Contributor (Humane Intelligence)

- **UNESCO Red Teaming Playbook: Tackling Gender Bias and Harms in AI**
  Research contributor

---

## RECOGNITION & SPEAKING

- **2026 AAAI-26** — Invited Talk: "Beyond the Rashomon Effect: Predictive Multiplicity in Multiagent Systems"
- **2026 APART Defense Acceleration Hackathon** — Finalist
- **2025 RecSys FAccTRec Workshop** — Invited Talk (with Oxford + Amazon)
- **2025 UN ITU AI for Good × Princeton** — Winner, "Future Leaders in Quantum"
- **2025 Humane Intelligence Bias Bounty 4** — Winner, Advanced Data Track
- **2024 ACM SIGGRAPH** — Invited Speaker, Frontiers Talk
- **2024 Oregon Entrepreneur of the Year** — Nominee

---

## TECHNICAL SKILLS

**ML & Research:** PyTorch, TensorFlow, JAX, Hugging Face, TransformerLens, Inspect, Neuropedia
**Agentic Systems:** MCP, AgentDevelopmentKit, evaluation harnesses, benchmark design
**Cloud & Infrastructure:** GCP (Vertex AI, BigQuery, Kubernetes), NVIDIA tools, hyperscaling
**Quantum:** Qiskit, PennyLane, IonQ, Cirq, Qbraid
**Development:** Python, TypeScript, JavaScript, VS Code, GitHub, Colab, Jupyter
**APIs:** Anthropic, OpenAI, Gemini, Mistral

---

## AFFILIATIONS

MLCommons • Humane Intelligence • Open Compute Project • ACM • AAAI • IEEE
AI for Good (ITU) • Algorithmic Justice League • The Sol Foundation • Google Women Techmakers

---

## RESEARCH FOCUS

- AI Safety Benchmarking & Evaluation Design
- Mechanistic Interpretability & Adversarial ML
- Multi-Agent Systems & Cascade Failure Analysis
- Quantum Security & Post-Quantum Cryptography
- Algorithmic Justice for Creative Industries

---

## EDUCATION

**Political Science** | George Washington University
**Self-Directed AI/ML Research** (2022–Present) — Deep learning, MI, quantum computing

---

## DIFFERENTIATOR

20 years of **forensic security, crisis operations, and live systems production** provide unique perspective on AI safety:
- Real-time threat assessment and adversarial behavior analysis
- Complex systems failure modes and mitigation strategies
- Human-scale risk assessment applied to AI systems

Previous career: Produced 100+ high-stakes events for HBO, Marvel, Vice, Red Bull, Intel. Founded first non-alcoholic bar on West Coast (2021). Crisis communication and incident response specialist.

---

*Full CV, research samples, and portfolio available upon request.*
