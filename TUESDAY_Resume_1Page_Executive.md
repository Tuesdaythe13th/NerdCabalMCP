# TUESDAY
**AI Safety Engineer • Mechanistic Interpretability • Adversarial ML**

Portland/LA/NYC (Remote) • [LinkedIn](#) • [GitHub](#) • [Scholar](#) • [Contact](#)

---

## PROFILE

Published ML engineer specializing in **AI safety benchmarking, mechanistic interpretability, and adversarial ML**. Contributor to NIST AI 700-2, MLCommons benchmarks (AILuminate v1.0, Security Jailbreak v0.5), and UN AI governance. Co-founder of MLCommons Agentic AI Working Group. Winner: UN ITU Future Leaders in Quantum (2025), Humane Intelligence Bias Bounty 4 (2025). 20 years forensic security background provides unique lens on real-time risk and failure mode analysis.

---

## EXPERIENCE

**Research Engineer** | APART Research Studio Lab • 2024–Present
Mechanistic interpretability research; "AI Psychosis" framework for LLM cognitive failure analysis

**Founder & Director** | ARTIFEX Labs • 2023–Present
Independent AI safety lab; published RecSys 2025 on cascade failures; designed clinical diagnostic frameworks for AI

**Technical Contributor & WG Co-Founder** | MLCommons • 2023–Present
Agentic AI WG (Co-Founder) • AILuminate v1.0 benchmark (arXiv:2404.03555) • Security Jailbreak v0.5 • ARES development

**Technical Red Teamer** | Humane Intelligence • 2023–Present
NIST AI 700-2 contributor • UNESCO Red Teaming Playbook • Bias Bounty 4 Winner • Policy-relevant audits

**Quantum Futures Contributor** | Open Compute Project • 2024–Present
Post-quantum cryptography, quantum data center security, error correction research

---

## KEY PUBLICATIONS

- **Cascade Failures in Recommender Systems** • RecSys 2025 • arXiv:2509.20099
- **AILuminate v1.0: AI Risk & Reliability Benchmark** • MLCommons • arXiv:2404.03555
- **Security Jailbreak Benchmark v0.5** • MLCommons (ISO/IEC 42001-aligned)
- **NIST AI 700-2 ARIA Pilot** • Contributor (Humane Intelligence)
- **UNESCO Red Teaming Playbook** • Research contributor

---

## RECOGNITION

**2026:** AAAI Invited Talk (Predictive Multiplicity) • APART Defense Hackathon Finalist
**2025:** UN ITU/Princeton Future Leaders in Quantum Winner • RecSys Invited Talk • Bias Bounty 4 Winner
**2024:** ACM SIGGRAPH Invited Speaker • Oregon Entrepreneur Nominee

---

## TECHNICAL EXPERTISE

**ML/Research:** PyTorch, JAX, TensorFlow, TransformerLens, Inspect, Hugging Face
**Agentic:** MCP, AgentDevelopmentKit, benchmark design, eval harnesses
**Cloud:** GCP (Vertex AI, BigQuery, Kubernetes), NVIDIA tools
**Quantum:** Qiskit, PennyLane, IonQ, Cirq
**Languages:** Python, TypeScript, JavaScript

---

## RESEARCH FOCUS

AI Safety Benchmarking • Mechanistic Interpretability • Adversarial ML & Red Teaming
Multi-Agent Reliability • Cascade Failure Analysis • Quantum Security • Algorithmic Justice

---

## AFFILIATIONS

MLCommons • Humane Intelligence • OCP • ACM • AAAI • IEEE • AI for Good (ITU) • AJL • Sol Foundation

---

## EDUCATION

**Political Science** | George Washington University
**Self-Directed AI/ML** (2022–Present) | Deep learning, MI, quantum computing

---

## UNIQUE DIFFERENTIATOR

**Forensic Security Background:** 20 years crisis operations, incident response, complex systems production (100+ high-stakes events for HBO, Marvel, Vice, Red Bull, Intel). This informs AI safety work with real-world understanding of adversarial behavior, failure cascades, and real-time threat mitigation at human scale—perspective most ML researchers lack.
