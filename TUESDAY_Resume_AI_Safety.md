# TUESDAY

**Advancing Frontier AI Safety and Mechanistic Evaluations**

[LINKTREE](#) | [LINKEDIN](#) | [GITHUB](#) | [HUGGINGFACE](#) | [ORCID](#) | [SCHOLAR](#) | [CONTACT](#)

Portland, Los Angeles, New York (Remote-First) • Open to Relocation (London preferred)

---

## EXECUTIVE SUMMARY

Published machine learning engineer and evaluation researcher pioneering **clinically-inspired diagnostics for frontier AI systems**. I apply biological and cognitive failure models to evaluation design, red teaming, and agentic risk analysis—developing what I call the "DSM for AI Systems."

My work spans **mechanistic interpretability, adversarial ML, quantum security, and multi-agent reliability**, contributing to domestic and international assurance standards through partnerships with NIST, CISA, UN ITU, Google DeepMind, Anthropic, Oxford, Amazon, and NVIDIA.

**Unique differentiator:** 20 years of forensic security, crisis operations, and high-stakes live systems production inform my approach to AI safety—I understand failure modes, adversarial behavior, and real-time risk mitigation at human scale.

---

## CORE EXPERTISE

**AI Safety & Evaluation Architecture**
- Mechanistic evaluations, benchmark design, evaluation harnesses, diagnostic frameworks
- Red teaming (multimodal, agentic), jailbreak taxonomies, adversarial ML
- Socio-technical risk analysis (SCAI risk, epistemic coercion, dissociative reasoning)

**Research Engineering**
- PyTorch, TensorFlow, JAX, TransformerLens, Inspect, Hugging Face ecosystem
- Agentic systems (MCP, AgentDevelopmentKit), multi-agent reliability analysis
- GCP (Vertex AI, BigQuery, Kubernetes), NVIDIA tools, hyperscaling architectures

**Emerging Technologies**
- Quantum computing (Qiskit, PennyLane, IonQ, Cirq), post-quantum cryptography
- Multimodal systems, cascade failure analysis, supply chain security

**Cross-Disciplinary Skills**
- Forensic security, incident response, crisis communication
- Complex systems production, adversarial pattern recognition, real-time threat assessment

---

## PROFESSIONAL EXPERIENCE

### Research Engineer | APART Research Studio Lab Fellowship Track
*2024 – Present*

- Conducting mechanistic interpretability research on AI cognitive failure modes
- Developing "AI Psychosis" framework: neural forensic analysis of dissociative reasoning patterns
- Contributing to experimental MI techniques and cognitive-affective modeling

### Founder & Director of Research | ARTIFEX Labs
*2023 – Present*

- Leading independent research lab focused on AI safety, interpretability, and quantum systems
- Published work on cascade failures, recommender system risks, and agentic maturity models
- Designed evaluation frameworks bridging clinical diagnostics and ML safety

### Technical Contributor & Working Group Co-Founder | MLCommons
*2023 – Present*

**Agentic AI Working Group** (Co-Founder)
- Released **Agentic Product Maturity Model** (2025) — industry-first framework for agentic system evaluation
- Contributing to **ARES** (Agentic Risk Evaluation Suite) benchmark development
- Designed evaluation patterns for multi-agent cascade failures and reliability metrics

**AI Safety Working Group**
- Lead contributor: **AILuminate v1.0** (arXiv:2404.03555) — comprehensive AI risk & reliability benchmark
- **Security Jailbreak Benchmark v0.5** — ISO/IEC 42001-aligned safety and resilience metrics
- MLPerf Automotive Benchmarking Task Force — safety-critical AI systems evaluation

### Technical Red Teamer & Safety Researcher | Humane Intelligence
*2023 – Present*

- **NIST AI 700-2 ARIA 0.1 Pilot Evaluation** — contributed red-teaming research cited in federal AI trustworthiness guidelines
- **UNESCO Red Teaming Playbook** — research contributor for gender bias and AI harms mitigation
- **Bias Bounty 4 Winner (2025)** — Advanced Data Track (Accessibility) for novel multimodal auditing techniques
- Conducting policy-relevant audits and multimodal red teaming for frontier models

### Quantum Futures Research Contributor | Open Compute Project (FTI)
*2024 – Present*

- Contributing to post-quantum cryptography and hardware security for quantum data centers
- Researching quantum error correction, supply chain economics, and near-quantum security
- Designing evaluation frameworks for quantum-classical hybrid systems

### Independent AI/ML Consultant | Self-Employed
*2022 – Present*

- Mechanistic interpretability, evaluation design, adversarial ML for private clients
- Benchmark design as a service for AI safety organizations
- Forensic security consulting: incident response, crisis communication, reputational risk mitigation

---

## SELECTED PUBLICATIONS

**Cascade: Human-in-the-Loop Shortcomings Can Increase the Risk of Failures in Recommender Systems**
*FAccTRec@RecSys 2025* • arXiv:2509.20099
Workshop Presentation at RecSys 2025

**AILuminate v1.0: AI Risk & Reliability / Generative AI Safety Benchmark**
*MLCommons* • arXiv:2404.03555
Comprehensive benchmark for generative AI safety evaluation

**MLCommons Security Jailbreak Benchmark v0.5**
Safety and resilience gap metrics for ISO/IEC 42001-aligned governance

**NIST AI 700-2: Trustworthy & Responsible AI — ARIA 0.1 Pilot Evaluation Report**
Contributor via Humane Intelligence

**UNESCO Red Teaming Playbook: Tackling Gender Bias and Harms in AI**
Red-teaming research contributor (Humane Intelligence)

**Beyond the Benchmark: Ethical AI Evaluation for Creative Communities in Mental Health**
*Stanford AIMI Symposium* — Finalist

**Aspirational Game Play: Improving Patient Care with AI-Powered Video Games**
*ACM SIGGRAPH 2024* — Frontiers, Invited Talk

---

## SELECTED SPEAKING ENGAGEMENTS & RECOGNITION

- **2026 AAAI-26 Invited Talk** — "Beyond the Rashomon Effect: Predictive Multiplicity in Multiagent Systems"
- **2026 APART Research Defense Acceleration Hackathon** — Finalist
- **2025 RecSys FAccTRec Workshop** — Invited Talk on cascade failures (with Oxford + Amazon)
- **2025 UN ITU AI for Good × Princeton Challenge** — Winner, "Future Leaders in Quantum"
- **2024 ACM SIGGRAPH** — Invited Speaker, Frontiers Talk
- **2024 Oregon Entrepreneur of the Year** — Nominee
- **2025 Humane Intelligence Bias Bounty 4** — Winner, Advanced Data Track (Accessibility)

---

## TECHNICAL STACK

**ML & Research:** PyTorch, TensorFlow, JAX, Hugging Face Transformers, TransformerLens, Inspect, Transluce Docent, Neuropedia

**Agentic & Emerging:** MCP servers, AgentDevelopmentKit, evaluation harnesses, benchmark design, agentic SDKs

**Cloud & Infrastructure:** GCP (Vertex AI, BigQuery, Kubernetes), NVIDIA developer suite, OpenUSD, hyperscaling architectures

**Quantum Platforms:** Qbraid, Qiskit, PennyLane, IonQ, Cirq

**Development Tools:** VS Code, GitHub, Colab, Jupyter, Replit, Claude Code, OpenAI Codex

**APIs & Models:** Anthropic, OpenAI, Gemini, Mistral

**Languages:** Python, TypeScript, JavaScript (full-stack focus)

**Productivity & Viz:** Figma, NotebookLM, Linear, Slack, Hex, Bokeh, Google Workspace

---

## AFFILIATIONS & MEMBERSHIPS

MLCommons • Humane Intelligence • Open Compute Project (FTI) • Cloud Security Alliance
ACM • AAAI • IEEE • Open Source Initiative • Content Authenticity Initiative
AI for Good (ITU) • Environmental Defense Fund • IAISI • Algorithmic Justice League
WIPO Young • EFF • The Sol Foundation • Cognitive Security Institute • Google Women Techmakers

---

## RESEARCH FOCUS AREAS

**AI Safety Benchmarking as a Service**
Socio-technical risk analysis across agentic, multimodal, and quantum-adjacent systems

**Evaluation Design & Clinical Diagnostics**
SCAI risk, epistemic coercion, dissociative reasoning; developing "DSM for AI Systems"

**Hyperscaling & Multi-Agent Systems**
Agentic maturity models, cascade failures, multi-agent reliability and safety

**Adversarial ML & Mechanistic Interpretability**
Jailbreaks, red teaming, neural tracing, exploit taxonomies, threat modeling

**Quantum Security & Supply Chain Economics**
Post-quantum cryptography, hardware-rooted security, quantum error correction

**Algorithmic Justice for Creative Industries**
IP rights, content authenticity, equitable compensation frameworks for artists and musicians

---

## WORK IN PROGRESS

**AI Psychosis Research** — Mechanistic exploration of dissociative reasoning in LLMs
[Sample Research Design](#)

**Neural Forensic Suite** — Diagnostic toolkit for LLM cognitive failure modes
[Demo: neuralforensicsuite.ipynb](#)

**The Mind Is Machine Readable** — Visual research synthesis
[Canva Presentation](#)

**The Benchmark Database** — Comprehensive AI evaluation catalog
[Canva Resource](#)

**AccessibilityDeepAgent** — Bias detection for accessibility features
[Project Demo](#)

---

## PREVIOUS CAREER HIGHLIGHTS

**Forensic Security & Crisis Operations (2015–2023)**
- Incident response, adversarial pattern analysis, post-incident reconstruction
- Crisis communication, reputational risk mitigation, high-stakes messaging
- Cyber-physical threat modeling, behavioral forensics, evidence preservation

**Hospitality & Live Performance Production (2004–2023)**
- Produced 100+ high-density, high-risk live events and immersive experiences
- Real-time operational triage, crowd dynamics, access control, performer safety
- Major clients: HBO, Playboy, Marvel, Vice, Red Bull, Intel, SXSW, Art Basel

**Notable Productions:**
- **Twin Peaks Bang Bang Bar** (HBO) — Immersive narrative activation
- **PLAYBOY's Hidden Arcade** — Multi-sensory experiential exhibit
- **Sucker Punch** (Founder, 2021) — First non-alcoholic cocktail bar on U.S. West Coast
- **Night on Broadway** — Festival-scale immersive programming (*LA Times* coverage)

*Why This Matters:* 20 years of real-time threat assessment, adversarial behavior analysis, and complex systems production inform my approach to AI safety—I understand failure modes, crisis mitigation, and human-scale risk in ways traditional ML researchers don't.

---

## EDUCATION

**Political Science** | George Washington University
Focus: International relations, policy analysis, strategic communication

**Self-Directed AI/ML Research** (2022–Present)
Deep learning, mechanistic interpretability, quantum computing, evaluation design

---

## PERSONAL STATEMENT

I am a **skeptical techno-optimist** committed to forging responsible, ecocentric technology frameworks. My decentralized intelligence model for R&D operates consortium-style, extending from Southern California to international bodies from Paris to Singapore.

Epically curious and a bonafide self-starter with world-class mentors in music, fine art, and technology. Artist/engineer with a love of classical arts and a deep commitment to algorithmic justice, transparency, and creative industry protection.

Currently researching quantum systems, evaluation design, adversarial ML, experimental mechanistic interpretability, and cognitive-affective modeling alongside world-class institutions.

---

**Thank you for your time, attention, and consideration. I look forward to hearing from you!**

---

*Full CV, portfolio, and research samples available upon request.*
